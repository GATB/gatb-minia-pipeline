#!/usr/bin/env python

import sys, os
from subprocess import call, Popen, PIPE, check_output
import glob
sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0) #unbuffered print, solves badly ordered stdout on clusters
import multiprocessing
nb_cpus = multiprocessing.cpu_count()

prefix="assembly"

doc = """GATB Pipeline

Usage:

    %s [arguments]

Reads (mandatory, specify at least one of these parameters):

    --12 <filename>                 interleaved paired reads
    -1   <filename>                 non-interleaved paired reads (forward mates)
    -2   <filename>                                            (reverse mates)
    -s   <filename>                 single reads
    -l   <file_of_filenames>        list of single reads, one file name per line
    --mp-12  <filename>             same input as paired reads (--12) but for mate pairs
    --mp-1   <filename>             same input as paired reads (-1 -2) but for mate pairs
    --mp-2   <filename>              
Advanced parameters (optional):

    -o <string>                     prefix of the output files (default: assembly)
    -c <filename>                   filename of contigs, will only perform scaffolding+gapfilling
    --step <step>                   step size to control increments of k values (default: 20)
    --kmer-sizes <k1>,<k2>,..       comma-separated list of k-mer sizes (default: 21,21+step,21+2*step,..)
    --abundance-mins <t1>,<t2>,..   list of low abundance thresholds (default: 2,2,2,..)
    --restart-from <k>              k value where to restart the multi-k process (useful for interrupted jobs)
    --max-memory <int>              go faster by using more memory (in MB) (default: as much as Minia needs)
""" % (sys.argv[0])

paired_reads = []
mate_pairs = []
unpaired_reads = []
contigs = None
list_k_values = []
list_min_abundances = []
k_restart = -1
step = 20
max_memory = - 1
nb_cores = int(check_output(["nproc"]))  # for bloocoo

#scaffolding_method="superscaffolder"
#scaffolding_method="sspace"
scaffolding_method="besst"

# this used to be false, now it's default
multi_k_mode = True
metagenomics = True
use_bloocoo_preprocessing = True

try:
    #TODO: now that it has a clean cmdline arguments structure, use docopt or something
    skip = 1 # this was formerly to handle paired-end case (-p XX XX) but it's not needed anymore now
    library = ""
    for i,arg in enumerate(sys.argv):
        if skip > 0:
            skip -= 1
            continue
        skip = 1
        if arg == "--12" or arg == "--mp-12":
           library = sys.argv[i+1]
           paired_reads.append(library) # list of all pairendd/matepairs reads
           if arg == "--mp-12":
               mate_pairs.append(library) # remember which are matepairs
        elif arg == "-1" or arg == "--mp-1":
           library = sys.argv[i+1]
        elif arg == "-2" or arg == "--mp-2":
           if library == "":
               exit("missing -1 parameter")
           library += " " + sys.argv[i+1]
           paired_reads.append(library) # list of all pairendd/matepairs reads
           if arg == "--mp-2":
               mate_pairs.append(library) # remember which are matepairs
           library = ""
        elif arg == "-s":
           unpaired_reads.append(sys.argv[i+1])
        elif arg == "-c":
           contigs = sys.argv[i+1]
        elif arg == "--kmer-sizes":
           list_k_values = map(int,sys.argv[i+1].split(','))
        elif arg == "--abundance-mins":
           list_min_abundances = map(int,sys.argv[i+1].split(','))
        elif arg == "-l":
            unpaired_reads = open(sys.argv[i+1]).read().splitlines()
        elif arg == "-o":
            prefix = sys.argv[i+1]
        elif arg == "--restart-from":
            k_restart = int(sys.argv[i+1])
        elif arg == "--step":
            step = int(sys.argv[i+1])
        elif arg == "--max-memory":
            max_memory = int(sys.argv[i+1])

        # special cases: 0-parameters arguments, need for "skip=0", well one day i'll use getopt
        elif arg == "--sspace":  #hidden parameter, for now
            scaffolding_method = "sspace" 
            skip = 0
        elif arg == "--no-error-correction":
            use_bloocoo_preprocessing = False
        elif arg in ["-h", "-help", "--help"]:
            raise Exception("Displaying help") 
        else:
            print("Unknown parameters", arg)
            raise Exception("Displaying help") 
    if len(paired_reads) + len(unpaired_reads) == 0:
        raise Exception("Please input at least one read dataset") 
except:
    import traceback
    traceback.print_exc()
    print doc
    sys.exit(1)

DIR = os.path.dirname(os.path.realpath(__file__))

def execute(program, cmdline=[], interpreter=None, stdout=None, memused=False):
    ret = 0
    try:
        cmd = []
        if memused:
            cmd += [ "%s/tools/memused" % DIR ]
        if interpreter:
            cmd += [interpreter]
        if program is not None:
            cmd += [ "%s/%s" % (DIR, program) ] 
        cmd += map(str, cmdline)
        program_string = ((interpreter + " ") if interpreter is not None else "") + (program if program is not None else "")
        print >>sys.stderr, "Execution of '%s'. Command line: \n     %s" % (program_string, ' '.join(cmd))
        ret = call(cmd, stdout=stdout)
    except OSError as e:
        print >>sys.stderr, "Exception:",e
        ret = 1
    if ret:
        print >>sys.stderr, "Execution of '%s' failed. Command line: \n     %s" % (program_string, ' '.join(cmd))
        exit(1)

list_reads = prefix + ".list_reads"
final_assembly = prefix + ".fasta"

def create_list_reads(extra_reads = [], append = False):
    # create of flat text file with all reads
    if append == True:
        local_list = extra_reads
        open_mode = "a"
    else:
        local_list = paired_reads + unpaired_reads + extra_reads
        open_mode = "w"

    with open(list_reads, open_mode) as f:
        for read in local_list:
            for filename in read.strip().split():
                if not os.path.exists(filename):
                    exit("Read file %s does not exist" % filename)
                f.write(filename + "\n")

# ------------------------------
# minia

def minia(k, min_abundance, prefix):
    global contigs
    if k == 0:
        exit('cannot execute minia with k=0')

    params = ['-in', list_reads, '-kmer-size', k, '-abundance-min', min_abundance, '-out', prefix]
    
    if max_memory != -1:
        params += ['-max-memory',max_memory]

    if k >= 128:
        params += ['-debloom','original'] # fix for large k values

    execute('minia/minia', params, memused=True)
    contigs = prefix + ".contigs.fa"
    return contigs

# ------------------------------
# wrapper for bloocoo

def bloocoo(output_file_prefix, threshold=2, kmer_size=31):

    # bloocoo command line arguments
    corrected_fasta = output_file_prefix + ".corrected_with_bloocoo.fa"
    params = ['-file', list_reads, '-out', corrected_fasta, '-abundance-min', threshold, 
              '-kmer-size', kmer_size, '-nb-cores', nb_cores , '-slow', '-high-precision']
    print "Running bloocoo on ", nb_cores, "cores"
    # call bloocoo
    execute('bloocoo/Bloocoo', params)

    # return a text file with the name of the bloocoo corrected data file
    list_reads_with_bloocoo_corrections = output_file_prefix + "_corrected_with_bloocoo.list_reads"
    with open(list_reads_with_bloocoo_corrections,"w") as f:
        f.write(corrected_fasta + "\n")
    return list_reads_with_bloocoo_corrections

# ------------------------------
# superscaffolder

def superscaffolder(contigs,library,output_filename=""):
    execute("superscaffolder/superscaffolding.py", [contigs, library, "-o", output_filename], interpreter="python", memused=True)

#-------------------------------
# sspace wrapper

def get_paired_end_parameters(contigs, library, is_mate_pairs = False):
    paired_reads = library.split(' ')
    cmd = ["%s/tools/estimate-insert-sizes" % DIR, contigs] + paired_reads
    if is_mate_pairs:
        cmd += ["--RF"] # force mate pairs
    output = Popen(cmd, stdout=PIPE).communicate()[0]
    orientation, mean, stdev = None, None, None
    for line in output.split('\n'):
        if line.startswith('Orientation'):
            l = line.split()
            orientation, mean, stdev = l[1], int(l[3]), int(l[5])
    print "GATB-Pipeline estimated insert size of library", paired_reads, ":", mean, stdev, orientation
    return orientation, mean, stdev
    
def possibly_gunzip(filename, lib_index, paired_index=None):
    if filename.endswith('.gz'):
        unzipped_filename = '.'.join(filename.split(".")[:-1])
        ext = unzipped_filename.split(".")[-1]
        output = prefix + '.lib%d' % lib_index 
        if paired_index:
            output += "_%d" % paired_index
        output += "." + ext
        print "Gunzipping", filename, "to", output
        outfile = open(output, 'wb')
        execute(None, ['-c', filename], interpreter='gunzip', stdout=outfile)
        outfile.close
        return output 
    return filename

def sspace(contigs, paired_reads, output_filename=""):
    # create a sspace config file
    lib_file = prefix + '.sspace.config'
    with open(lib_file, 'w') as f:
        for i, library in enumerate(paired_reads):
            is_mate_pairs = library in mate_pairs
            # sspace needs de-interleaved input
            if ' ' not in library:
                library = possibly_gunzip(library, i)
                print "Splitting interleaved file:", library
                ext = library.split(".")[-1]
                p1, p2 = [prefix + ".lib%d_%d." % (i,j) + ext for j in [1,2] ]
                #de-interleave reads using SGA's script (was too lazy to write my own)
                execute('tools/sga-deinterleave.pl', [library, p1, p2], interpreter="perl")
                library = p1 + " " + p2
            else:
                # sspace basic cannot work with gzipped files
                p1, p2 = library.split(' ')
                library = possibly_gunzip(p1, i, 1) + ' ' + possibly_gunzip(p2, i, 2)

            # estimate insert size
            orientation, mean, stdev = get_paired_end_parameters(contigs, library, is_mate_pairs)
            if orientation is None:
                exit("Error running estimate-insert-sizes for library: %s" % library)

            # sspace error isn't exactly the stdev; subjectively, I'm converting using 3 sigmas
            error = min(max(0.1, stdev * 3.0 / mean),0.9)
            f.write('lib%d %s %d %0.1f %s\n' % (i, library, mean, error, orientation))

    # run sspace
    cmd = ['-l', lib_file, '-s', contigs, '-b', prefix + '.sspace']
    execute('sspace/SSPACE_Basic_v2.0.pl', cmd, interpreter="perl", memused=True)
    print "SSPACE is done! the maximal memory used above was for SSPACE only"

    # clean up intermediate sspace files
    

# ------------------------------
# besst wrapper

def run_besst_mapping(i, contigs, library):
    # besst needs de-interleaved input, for the mapping phase (else it thinks they're single end)
    if ' ' not in library:
        library = possibly_gunzip(library, i) # until sga-deinterleave supports gzipped input, no other choice but to gunzip
        print "Splitting interleaved file:", library
        ext = library.split(".")[-1]
        p1, p2 = [prefix + ".lib%d_%d." % (i,j) + ext for j in [1,2] ]
        #de-interleave reads using SGA's script (was too lazy to write my own)
        execute('tools/sga-deinterleave.pl', [library, p1, p2], interpreter="perl")
        library = p1 + " " + p2
    paired_reads = library.split(' ')

    output_bam = prefix + '.lib_%d' % i
    os.environ["TEMP"] = os.getcwd() # besst uses tempfile which uses $TEMP to store mapping data
    # bwa mem produces wrong contamination estimates (see assemblathon dataset)
    execute('BESST/scripts/reads_to_ctg_map.py', ["--nomem", "--threads", nb_cpus] + paired_reads + [contigs, output_bam], interpreter="python")
    return output_bam + ".bam"

# besst needs python >= 2.7, see if we have it installed on the system somewhere
def check_for_python_27():
    for i, python27 in enumerate(['python', 'python2.7', 'python-2.7']):
        try:
            ret = call([python27, "-c", "from collections import Counter"])#,stdout=PIPE,stderr=PIPE)
        except:
            ret = 1
        if ret == 0:
            if i > 0:
                print "found Python 2.7 via command:", python27
            return python27
    exit("BESST needs Python >= 2.7, make sure it is aliased to either the 'python' or the 'python2.7' command on your shell")


def besst(contigs, bam_files, orientations, output_filename=""):
    global k, final_assembly
    interpreter = check_for_python_27()
    filter_contigs = (200 if len(mate_pairs) == 0 else 1000) #hacky
    cmd = ['-c', contigs, '-f'] + bam_files + ['--orientation'] + orientations + ['--no_score', '-filter_contigs', filter_contigs, '-o', prefix + '_besst', '-K', k]
    execute('BESST/runBESST', cmd, interpreter=interpreter, memused=True)
    besst_scaffolds = sorted(glob.glob(prefix + "_besst/BESST_output/pass*/*.fa"))
    if len(besst_scaffolds) == 0:
        exit("Error: BESST returned no results in %s" % (prefix + "_besst/"))
    last_pass = besst_scaffolds[-1]
    if os.path.exists(final_assembly):
        os.remove(final_assembly)
    os.symlink(last_pass, final_assembly)
    print "BESST is done! the maximal memory used above was for BESST only"
    

# ------------------------------
# wrapper for scaffolding

def scaffold(contigs, paired_reads):
    if scaffolding_method == "superscaffolder":
        # superscaf takes one library at a time
        for i, paired_read in enumerate(paired_reads):
            input_file = prefix + ".scaffolds%d.fa" % i if i > 0 else contigs
            output_file = prefix + ".scaffolds%d.fa" % (i+1)
            superscaffolder(input_file,paired_read,output_file)
    elif scaffolding_method == "sspace":
        sspace(contigs,paired_reads)
    elif scaffolding_method == "besst":
        # besst needs pre-mapping one library at a time
        bam_files, orientations = [], []
        for i, paired_read in enumerate(paired_reads):
            bam_files += [run_besst_mapping(i,contigs,paired_read)]
            orientations += [ 'rf' if paired_read in mate_pairs else 'fr' ]
        besst(contigs,bam_files, orientations)

# ------------------------------
# auxiliary function

def get_read_length(list_reads):
    read_lengths = []
    for library in list_reads:
        if ' ' in library:
            reads_list = library.split(' ')
        else:
            reads_list = [library]
        for reads_file in reads_list:
            try:
                import gzip
                fp = gzip.open(reads_file)
                ln = fp.read(2) # read arbitrary bytes to check if gzipped 
            except Exception,e:
                fp.close()
                fp = open(reads_file)  
            # read the 1000 first reads
            from tools.readfq import readfq
            read_count = 0
            for name, seq, qual in readfq(fp):
                read_count += 1
                read_lengths += [len(seq)]
                if read_count > 1000:
                    break
            fp.close()

    # so, on CEA cluster, loading numpy forced minia to run on a single thread. so let's not use numpy here. days of debugging to get that.
    import math
    def percentile(data, percentile):
        size = len(data)
        return sorted(data)[int(math.ceil((size * percentile) / 100)) - 1]

    estimated_max_read_length = percentile(read_lengths,90)
    print "Setting maximum kmer length to:", estimated_max_read_length, "bp" # based on the 90 percentile of 1000 first reads lengths of each input file
    return estimated_max_read_length

# ------------------------------
# main pipeline

create_list_reads()

if use_bloocoo_preprocessing == True:

    # call bloocoo
    list_reads_corrected = bloocoo(output_file_prefix=prefix)

    # now list_reads contains only the bloocoo output filename
    os.rename(list_reads_corrected,list_reads)


if len(list_k_values) == 0:
    max_k = get_read_length(paired_reads + unpaired_reads) #TODO: modify bloocoo so that it gives a read length histogram, rather than using this hacky procedure
    if max_k <= 21:
        sys.exit("Reads are shorter than 21 base pairs? (%d bp at 90 percentile of read lengths over the first 1000 reads of each input file).\nNotify a developer if this estimation was wrong, or if your reads are really that short, please set the list of kmer lengths manually using the --kmer-sizes parameter" % max_k)
    # two implicit assumptions: do not make more than 20 rounds, and start at k=21 
    for i in xrange(20): 
        k = 21 + i*step
        if k <= max_k and k <= 256: #max supported in minia binary is 256
            list_k_values += [k]

if len(list_min_abundances) == 0:
    list_min_abundances = [2]*len(list_k_values)

cutoffs = sorted(zip(list_k_values, list_min_abundances))

if k_restart == -1:
    print "Multi-k values and cutoffs: ",cutoffs
else:
    print "*** restart mode"
    cutoffs_keys = sorted([x for x in dict(cutoffs).keys()])
    last_k_value_before_restart = cutoffs_keys[cutoffs_keys.index(k_restart)-1]
    print "*** pipeline restart mode: k_restart=%d (last_k_value_before_restart=%d) *** " % (k_restart, last_k_value_before_restart)
    cutoffs = sorted([(key,dict(cutoffs)[key]) for key in cutoffs_keys if key >= k_restart])
    print "Restarting GATB-pipeline with cutoffs ", cutoffs
    print "This assumes that an assembly with k =", last_k_value_before_restart, "exists."

last_k_value = 0
previous_contigs = None if k_restart == -1 else  prefix+"_k%d.contigs.fa"%last_k_value_before_restart
for k in sorted(dict(cutoffs).keys()):
    if k < last_k_value + step and not metagenomics:
        continue
    min_abundance = dict(cutoffs)[k]
    print "Multi-k GATB-Pipeline, Minia assembling at k=%d min_abundance=%d" % (k, min_abundance)
    extra_reads = [previous_contigs]*(min_abundance+1) if previous_contigs is not None else []
    create_list_reads(extra_reads, append=True)
    multi_k_prefix = prefix + "_k%d" % k
    previous_contigs = minia(k, min_abundance, prefix=multi_k_prefix)
    last_k_value = k
k = last_k_value # hint for besst
print "Finished Multi-k GATB-Pipeline at k=%d" % last_k_value

# scaffolding all libraries
if len(paired_reads) > 0:
    scaffold(contigs, paired_reads)
else:
    if os.path.exists(final_assembly):
        os.remove(final_assembly)
    os.symlink(contigs, final_assembly)
 
print "pipeline finished!! assembly is in: %s" % final_assembly
